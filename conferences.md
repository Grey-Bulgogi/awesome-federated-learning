# Federated Learning Paper in Conferences

## NIPS

### NeurIPS 2020

* Personalized Federated Learning with Moreau Envelopes [[Paper]](https://arxiv.org/abs/2006.08848)
* Lower Bounds and Optimal Algorithms for Personalized Federated Learning [[Paper]](https://papers.nips.cc/paper/2020/file/187acf7982f3c169b3075132380986e4-Paper.pdf) [KAUST]
* Personalized Federated Learning with Theoretical Guarantees: A Model-Agnostic Meta-Learning Approach [[Paper]](https://papers.nips.cc/paper/2020/file/24389bfe4fe2eba8bf9aa9203a44cdad-Paper.pdf) [MIT]
* Federated Principal Component Analysis [[Paper]](https://papers.nips.cc/paper/2020/file/47a658229eb2368a99f1d032c8848542-Paper.pdf) [Cambridge]
* FedSplit: an algorithmic framework for fast federated optimization [[Paper]](https://papers.nips.cc/paper/2020/file/4ebd440d99504722d80de606ea8507da-Paper.pdf) [Berkeley]
* Minibatch vs Local SGD for Heterogeneous Distributed Learning [[Paper]](https://papers.nips.cc/paper/2020/file/45713f6ff2041d3fdfae927b82488db8-Paper.pdf) [Toyota]
* Distributed Training with Heterogeneous Data: Bridging Median- and Mean-Based Algorithms [[Paper]](https://papers.nips.cc/paper/2020/file/f629ed9325990b10543ab5946c1362fb-Paper.pdf)
* Throughput-Optimal Topology Design for Cross-Silo Federated Learning [[Paper]](https://papers.nips.cc/paper/2020/file/e29b722e35040b88678e25a1ec032a21-Paper.pdf)
* Distributed Distillation for On-Device Learning [[Paper]](https://papers.nips.cc/paper/2020/file/fef6f971605336724b5e6c0c12dc2534-Paper.pdf) [Stanford]
* **Ensemble Distillation for Robust Model Fusion in Federated Learning** [[Paper]](https://papers.nips.cc/paper/2020/file/18df51b97ccd68128e994804f3eccc87-Paper.pdf) 
  * Nice experimentation graphs and comparison with FedAvg
* Group Knowledge Transfer: Federated Learning of Large CNNs at the Edge [[Paper]](https://papers.nips.cc/paper/2020/file/a1d4c20b182ad7137ab3606f0e3fc8a4-Paper.pdf) [USC]
* Federated Accelerated Stochastic Gradient Descent [[Paper]](https://papers.nips.cc/paper/2020/file/39d0a8908fbe6c18039ea8227f827023-Paper.pdf) [[Github]](https://github.com/hongliny/FedAc-NeurIPS20) [Stanford]
* Distributionally Robust Federated Averaging [[Paper]](https://papers.nips.cc/paper/2020/file/ac450d10e166657ec8f93a1b65ca1b14-Paper.pdf)
* An Efficient Framework for Clustered Federated Learning [[Paper]](https://papers.nips.cc/paper/2020/file/e32cc80bf07915058ce90722ee17bb71-Paper.pdf) [Berkeley]
* Robust Federated Learning: The Case of Affine Distribution Shifts [[Paper]](https://papers.nips.cc/paper/2020/file/f5e536083a438cec5b64a4954abc17f1-Paper.pdf) [MIT]
* Tackling the Objective Inconsistency Problem in Heterogeneous Federated Optimization [[Paper]](https://papers.nips.cc/paper/2020/file/564127c03caab942e503ee6f810f54fd-Paper.pdf) [CMU]
* Federated Bayesian Optimization via Thompson Sampling [[Paper]](https://papers.nips.cc/paper/2020/file/6dfe08eda761bd321f8a9b239f6f4ec3-Paper.pdf) [NUS] [MIT]
* Distributed Newton Can Communicate Less and Resist Byzantine Workers [[Paper]](https://arxiv.org/pdf/2006.08737.pdf) [Berkeley]
* Byzantine Resilient Distributed Multi-Task Learning [[Paper]](https://papers.nips.cc/paper/2020/file/d37eb50d868361ea729bb4147eb3c1d8-Paper.pdf)
* A Scalable Approach for Privacy-Preserving Collaborative Machine Learning [[Paper]](https://papers.nips.cc/paper/2020/file/5bf8aaef51c6e0d363cbe554acaf3f20-Paper.pdf) [USC]
* Inverting Gradients - How easy is it to break privacy in federated learning? [[Paper]](https://papers.nips.cc/paper/2020/file/c4ede56bbd98819ae6112b20ac6bf145-Paper.pdf) 
* Attack of the Tails: Yes, You Really Can Backdoor Federated Learning [[Paper]](https://papers.nips.cc/paper/2020/file/b8ffa41d4e492f0fad2f13e29e1762eb-Paper.pdf)
* Election Coding for Distributed Learning: Protecting SignSGD against Byzantine Attacks [[Paper]](https://papers.nips.cc/paper/2020/file/a7f0d2b95c60161b3f3c82f764b1d1c9-Paper.pdf)
* Differentially-Private Federated Linear Bandits [[Paper]](http://web.mit.edu/dubeya/www/files/dp_linucb_20.pdf) [[Slides]](http://web.mit.edu/dubeya/www/files/slides/nips20_fed.pdf) [MIT]

### NeurIPS 2019 Workshop

* NIPS 2019 Workshop on Federated Learning for Data Privacy and Confidentiality 1 [[Video]](https://slideslive.com/38921898/workshop-on-federated-learning-for-data-privacy-and-confidentiality-1)
* NIPS 2019 Workshop on Federated Learning for Data Privacy and Confidentiality 2 [[Video]](https://slideslive.com/38921899/workshop-on-federated-learning-for-data-privacy-and-confidentiality-2)
* NIPS 2019 Workshop on Federated Learning for Data Privacy and Confidentiality 3 [[Video]](https://slideslive.com/38921900/workshop-on-federated-learning-for-data-privacy-and-confidentiality-3)

## ICML

### ICML20

* FedBoost: Communication-Efficient Algorithms for Federated Learning [[Paper]](https://proceedings.icml.cc/static/paper_files/icml/2020/5967-Paper.pdf) [ICML20]
* FetchSGD: Communication-Efficient Federated Learning with Sketching [[Paper]](https://arxiv.org/abs/2007.07682) [ICML20]
* Federated Learning with Only Positive Labels [[Paper]](https://arxiv.org/pdf/2004.10342.pdf) [Google]
* SCAFFOLD: Stochastic Controlled Averaging for On-Device Federated Learning [[Paper]](https://arxiv.org/abs/1910.06378)
* From Local SGD to Local Fixed-Point Methods for Federated Learning [[Paper]](https://arxiv.org/pdf/2004.01442.pdf)
